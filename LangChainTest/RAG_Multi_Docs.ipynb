{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote import logging\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "import pandas\n",
    "from llama_parse import LlamaParse\n",
    "# from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jw\\AppData\\Local\\Temp\\ipykernel_20608\\3248108824.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embed_model = HuggingFaceEmbeddings(\n",
      "c:\\Users\\jw\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# embed model\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name = \"jhgan/ko-sroberta-nli\",\n",
    "    model_kwargs = {\"device\":\"cpu\"},\n",
    "    encode_kwargs = {\"normalize_embeddings\":True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature = 0,\n",
    "    model_name = \"gpt-4o-mini\",\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Split Embed function\n",
    "\n",
    "def LSE(fname):\n",
    "    \n",
    "    # Load\n",
    "    loader = TextLoader(fname, encoding = \"utf-8\")\n",
    "    data = loader.load()\n",
    "    splitter = CharacterTextSplitter(\n",
    "    separator = \"//<>\",\n",
    "    # chunk_size = size,\n",
    "    # chunk_overlap = overlap,\n",
    "    length_function = len\n",
    "    )\n",
    "\n",
    "    # Split\n",
    "    documents = splitter.split_documents(data)\n",
    "    \n",
    "    #Embed\n",
    "    vectorstore = FAISS.from_documents(documents,\n",
    "                                   embedding = embed_model,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE)\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Chain Response function\n",
    "\n",
    "def PCR(template, docs, query):\n",
    "    \n",
    "    # Prompt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # 이 부분은 뭔지 모르겠음\n",
    "    # def format_docs(docs):\n",
    "    #     return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = chain.invoke({\"context\": docs, \"question\":query})\n",
    "    return response\n",
    "\n",
    "\n",
    "# 당신은 광운대학교 학생인 사용자에게 사용자가 입력한 자신의 입학 연도를 기반으로 졸업 요건을 알려주는 인공지능 챗봇입니다.\n",
    "#             졸업 이수학점 표는 총 7열입니다. 이때 7열중 교양은 (필수+균형)과 기초라는 2열로 다시 나누어집니다.\n",
    "#             주전공학점(필수 포함)은 단일 전공시와 다전공 이수시로 2열로 나누어집니다.\n",
    "#             표에서 이웃한 여러 셀이 동일한 값을 가질 경우 그 열의 같은 값을 가지는 이웃한 셀들을 통합하기도 합니다.\n",
    "#             또한 이 문서는 각 졸업 요건이 동일한 입학 연도 단위 앞 부분에 가., 나., 다. ... 순으로 번호를 매깁니다.\n",
    "#             이 중 어떤 부분을 참고해서 답변 하였는지 맨 처음에 명시하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공학인증 chain\n",
    "\n",
    "# Engineering Chain\n",
    "def EChain(docs, query):\n",
    "    template1 = '''표의 내용에서 생략되는 정보 없이 모든 것을 출력해야 하며, 마크다운 형식으로 보기 편하게 출력하세요.\n",
    "            오직 다음의 context에 기반하여 대답하세요. {context}, Question: {question}'''\n",
    "    \n",
    "    vectorstore1 = LSE(docs[0].page_content)\n",
    "    retriever1 = vectorstore1.as_retriever(search_kwargs={'k': 1})\n",
    "    docs1 = retriever1.get_relevant_documents(query)\n",
    "    response1 = PCR(template1, docs1[0], query)\n",
    "\n",
    "    vectorstore2 = LSE(docs[1].page_content)\n",
    "    retriever2 = vectorstore2.as_retriever(search_kwargs={'k': 1})\n",
    "    docs2 = retriever2.get_relevant_documents(query)\n",
    "    response2 = PCR(template1, docs2, query)\n",
    "\n",
    "    template2 = '''오직 context1과 context2만을 참고하여 두 내용을 보기 좋게 생략되는 정보 없이 마크다운 형식으로 출력하세요.\n",
    "                {context1}, {context2}, Question: {question}'''\n",
    "    prompt = ChatPromptTemplate.from_template(template2)\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"context1\": response1, \"context2\": response2, \"question\":query})\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 25, which is longer than the specified 20\n",
      "Created a chunk of size 25, which is longer than the specified 20\n",
      "C:\\Users\\jw\\AppData\\Local\\Temp\\ipykernel_20608\\233103367.py:25: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "# file list embedding\n",
    "\n",
    "# Load\n",
    "loader = TextLoader(\"file_list.txt\", encoding = \"utf-8\")\n",
    "data = loader.load()\n",
    "splitter = CharacterTextSplitter(\n",
    "separator = \",\",\n",
    "chunk_size = 20,\n",
    "chunk_overlap = 0,\n",
    "length_function = len\n",
    ")\n",
    "\n",
    "# Split\n",
    "documents = splitter.split_documents(data)\n",
    "\n",
    "#Embed\n",
    "vectorstore = FAISS.from_documents(documents,\n",
    "                                embedding = embed_model,\n",
    "                                distance_strategy = DistanceStrategy.COSINE)\n",
    "\n",
    "query = \"2021학년도 소프트웨어학부 신입학자의 공학인증을 알려줘.\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "docs = retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공학인증제도 안내 - 졸업이수 요건.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4060, which is longer than the specified 4000\n",
      "Created a chunk of size 4396, which is longer than the specified 4000\n",
      "Created a chunk of size 4375, which is longer than the specified 4000\n",
      "Created a chunk of size 4278, which is longer than the specified 4000\n",
      "Created a chunk of size 4799, which is longer than the specified 4000\n",
      "Created a chunk of size 4772, which is longer than the specified 4000\n",
      "Created a chunk of size 4534, which is longer than the specified 4000\n",
      "Created a chunk of size 4803, which is longer than the specified 4000\n",
      "Created a chunk of size 4492, which is longer than the specified 4000\n",
      "Created a chunk of size 4212, which is longer than the specified 4000\n",
      "Created a chunk of size 4847, which is longer than the specified 4000\n",
      "Created a chunk of size 4655, which is longer than the specified 4000\n",
      "Created a chunk of size 4566, which is longer than the specified 4000\n",
      "Created a chunk of size 4692, which is longer than the specified 4000\n",
      "Created a chunk of size 4539, which is longer than the specified 4000\n",
      "Created a chunk of size 5424, which is longer than the specified 4000\n",
      "Created a chunk of size 4543, which is longer than the specified 4000\n",
      "Created a chunk of size 4511, which is longer than the specified 4000\n",
      "Created a chunk of size 4822, which is longer than the specified 4000\n",
      "Created a chunk of size 4552, which is longer than the specified 4000\n",
      "Created a chunk of size 4957, which is longer than the specified 4000\n",
      "Created a chunk of size 4834, which is longer than the specified 4000\n",
      "Created a chunk of size 4587, which is longer than the specified 4000\n",
      "Created a chunk of size 4402, which is longer than the specified 4000\n",
      "Created a chunk of size 4295, which is longer than the specified 4000\n",
      "Created a chunk of size 4446, which is longer than the specified 4000\n",
      "Created a chunk of size 4750, which is longer than the specified 4000\n",
      "Created a chunk of size 4070, which is longer than the specified 4000\n",
      "Created a chunk of size 4395, which is longer than the specified 4000\n",
      "Created a chunk of size 4164, which is longer than the specified 4000\n",
      "Created a chunk of size 4433, which is longer than the specified 4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 2024학번 입학자부터 적용 졸업요건\n",
      "\n",
      "| **졸업요건** | **졸업이수학점 : 133학점(필수 포함)** |\n",
      "| - | - |\n",
      "\n",
      "## 졸업요건 세부사항\n",
      "\n",
      "| 구분 | 학과 | 교양 | 전공 | 졸업요건 학점 | 최소 졸업요건 ‘공학필수’ |\n",
      "| - | - | - | - | - | - |\n",
      "| 전자 정보 공과 대학 | 전자공학과 | ① 학번에 따른 「교양 교과목 이수체계」참고<br>② MSC 24~30 학점<br>- 공학계열 단과 대학 학과별 「교양 및 MSC(수학, 기초 과학, 전산학) 교과 과정표」참고 | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 캡스톤설계 |  |\n",
      "|  | 전자통신공학과 |  | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 예비캡스톤설계, 캡스톤설계 |  |\n",
      "|  | 전자융합공학과 |  | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 캡스톤설계1 |  |\n",
      "|  | 전기공학과 |  | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 캡스톤설계 |  |\n",
      "|  | 전자재료공학과 |  | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 캡스톤설계1, 캡스톤설계2 |  |\n",
      "|  | 반도체시스템공학부 |  | 전공 전필 포함 60학점 (설계 12학점 포함) | 공학설계입문, 캡스톤종합설계1 |  |\n",
      "| 인공 지능 융합 대학 | 컴퓨터정보공학부\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)\n",
    "\n",
    "if docs[0].page_content == \"공학인증제도 안내 - 교양 및 교과과정표.md\" or docs[0].page_content == \"공학인증제도 안내 - 졸업이수 요건.md\":\n",
    "    EChain(docs, query)\n",
    "\n",
    "else:\n",
    "    print(\"1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
