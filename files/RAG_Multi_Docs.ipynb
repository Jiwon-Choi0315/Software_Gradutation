{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote import logging\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "import pandas\n",
    "from llama_parse import LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jw\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# embed model\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name = \"jhgan/ko-sroberta-nli\",\n",
    "    model_kwargs = {\"device':'cpu\"},\n",
    "    encode_kwargs = {\"normalize_embeddings\":True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature = 0,\n",
    "    model_name = \"gpt-4o-mini\",\n",
    "    max_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Split Embed function\n",
    "\n",
    "def LSE(fname):\n",
    "    \n",
    "    # Load\n",
    "    loader = TextLoader(fname.page_content, encoding = \"utf-8\")\n",
    "    data = loader.load()\n",
    "    splitter = CharacterTextSplitter(\n",
    "    separator = \"//<>\",\n",
    "    # chunk_size = size,\n",
    "    # chunk_overlap = overlap,\n",
    "    length_function = len\n",
    "    )\n",
    "\n",
    "    # Split\n",
    "    documents = splitter.split_documents(data)\n",
    "    \n",
    "    #Embed\n",
    "    vectorstore = FAISS.from_documents(documents,\n",
    "                                   embedding = embed_model,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE)\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Chain Response function\n",
    "\n",
    "def PCR(template, docs, query):\n",
    "    # Prompt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # 이 부분은 뭔지 모르겠음\n",
    "    # def format_docs(docs):\n",
    "    #     return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "    # Chain\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    # Run\n",
    "    response = chain.invoke({'context': docs, 'question':query})\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공학인증 chain\n",
    "\n",
    "# Engineering Chain\n",
    "def EChain(docs, query):\n",
    "    vectorstore1 = LSE(docs[0].page_content)\n",
    "    response1 = PCR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 25, which is longer than the specified 20\n",
      "Created a chunk of size 25, which is longer than the specified 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# load and split file_list\n",
    "\n",
    "f_loader = TextLoader(\"file_list.txt\", encoding = \"utf-8\")\n",
    "f_data = f_loader.load()\n",
    "f_splitter = CharacterTextSplitter(\n",
    "    separator = \",\",\n",
    "    chunk_size = 20,\n",
    "    chunk_overlap = 0,\n",
    "    length_function = len\n",
    ")\n",
    "\n",
    "f_documents = f_splitter.split_documents(f_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='공학인증제도 안내 - 졸업이수 요건.md' metadata={'source': 'file_list.txt'}\n"
     ]
    }
   ],
   "source": [
    "# embed and save file_list and retrieve\n",
    "\n",
    "f_vectorstore = FAISS.from_documents(f_documents,\n",
    "                                   embedding = embed_model,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE)\n",
    "\n",
    "\n",
    "query = \"2021학년도 소프트웨어학부 신입학자가 공학인증을 받고 졸업하기 위한 조건을 알려줘.\"\n",
    "\n",
    "f_retriever = f_vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "f_docs = f_retriever.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if f_docs[0].page_content[0:5] == \"공학인증제도\":\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and text split\n",
    "\n",
    "loader = TextLoader(f_docs[0].page_content, encoding = \"utf-8\")\n",
    "data = loader.load()\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator = \"//<>\",\n",
    "    # chunk_size = 4500,\n",
    "    # chunk_overlap = 500,\n",
    "    # length_function = len\n",
    ")\n",
    "\n",
    "documents = splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save embeddings in vectorstore\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents,\n",
    "                                   embedding = embed_model,\n",
    "                                   distance_strategy = DistanceStrategy.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query and retirever\n",
    "\n",
    "#query = '2019학년도 소프트웨어학부 신입학자가 졸업하기 위한 학점을 알려줘.'\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 1})\n",
    "\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# for i in docs:\n",
    "#     print(i.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021학년도 소프트웨어학부 신입학자가 공학인증을 받고 졸업하기 위한 조건은 다음과 같습니다:\n",
      "\n",
      "1. **최소 졸업 이수학점**: 133학점\n",
      "2. **전공학점(필수 포함)**: 60학점 (설계 12학점 포함)\n",
      "3. **교양 및 MSC(수학, 기초과학, 전산학)**: 12~30학점\n",
      "   - 소프트웨어학부의 경우: 12학점\n",
      "4. **교양 교과목 이수체계**: 해당 학과의 이수체계에 따라 이수\n",
      "5. **졸업논문 및 소속 학과별 졸업요건**: 학과 홈페이지 참조\n",
      "\n",
      "각 학과의 졸업요건 세부 사항은 해당 학과 내규에 따르므로 반드시 소속 학과로 문의해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "# generation\n",
    "\n",
    "\n",
    "# 당신은 광운대학교 학생인 사용자에게 사용자가 입력한 자신의 입학 연도를 기반으로 졸업 요건을 알려주는 인공지능 챗봇입니다.\n",
    "#             졸업 이수학점 표는 총 7열입니다. 이때 7열중 교양은 (필수+균형)과 기초라는 2열로 다시 나누어집니다.\n",
    "#             주전공학점(필수 포함)은 단일 전공시와 다전공 이수시로 2열로 나누어집니다.\n",
    "#             표에서 이웃한 여러 셀이 동일한 값을 가질 경우 그 열의 같은 값을 가지는 이웃한 셀들을 통합하기도 합니다.\n",
    "#             또한 이 문서는 각 졸업 요건이 동일한 입학 연도 단위 앞 부분에 가., 나., 다. ... 순으로 번호를 매깁니다.\n",
    "#             이 중 어떤 부분을 참고해서 답변 하였는지 맨 처음에 명시하세요.\n",
    "\n",
    "\n",
    "template = '''\n",
    "            오직 한가지 한 단위만 참고해서 답변해야 하며, 당신이 참고했다 말하는 부분만을 기반으로 답변해야 합니다.\n",
    "            생략되는 정보가 없어야 합니다.\n",
    "            만약 표에 나타나 있는 데이터를 참고해야 한다면, 마크다운 언어를 이용해 표 형식으로 출력하되, 병합된 셀이 있는지를 감안하세요.\n",
    "            오직 다음의 context에 기반하여 대답하세요. {context}, Question: {question}\n",
    "            '''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# 이 부분은 뭔지 모르겠음\n",
    "# def format_docs(docs):\n",
    "#     return '\\n\\n'.join([d.page_content for d in docs])\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "response = chain.invoke({'context': docs, 'question':query})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
